{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial titanic_problem_estimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senkmp/TensorFlow-2.0/blob/master/Tutorial_titanic_problem_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI7knaZK8jnd",
        "colab_type": "text"
      },
      "source": [
        "# How to train Linear model and boosted tree model in Tensorflow\n",
        "In this tutorial, we will see how to use tf.estimator.LinearClassifier model and tf.estimator.BoostedTreesClassifier to classify structured data (pandas dataframe)  with creating an input pipe line using feature columns ( tf.feature_column) and tf.data.\n",
        "\n",
        "you will learn-\n",
        "\n",
        "\n",
        "* Creating different types of feature columns using tf.feature_columns\n",
        "* Creating input data function using tf.data for train, val and test set\n",
        "* Creating, compiling and training of tf.estimator model \n",
        "* Evaluating model\n",
        "* Prediction on test data\n",
        "\n",
        "## The Dataset\n",
        "\n",
        "I have used [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview) from kaggle, you can [download](https://www.kaggle.com/c/3136/download-all) and find [description](https://www.kaggle.com/c/titanic/data) of dataset on kaggle. I have used google colab and hence uploaded data in google drive.\n",
        "\n",
        "## Mount google drive\n",
        "I have uploaded data on **google drive,** Learn How to use data from google drive [here](https://medium.com/ml-book/simplest-way-to-open-files-from-google-drive-in-google-colab-fae14810674)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BspuOkXyIoWw",
        "colab_type": "code",
        "outputId": "6b4ec5fe-eb63-4cdf-ae03-4eeeb06b57e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGxPQNtO60eD",
        "colab_type": "text"
      },
      "source": [
        "# Import TensorFlow and other libraries\n",
        "I have used Tensorflow nightly version which is unstable version (aug 2019)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP1u_-4EIsMB",
        "colab_type": "code",
        "outputId": "9da232d3-25ce-4906-afdb-4cc4a733978a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly-2.0-preview\n",
        "except Exception:\n",
        "  pass\n",
        "!pip install sklearn\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/2d/b478f71fd352b4b7c175b7bf04b74fd86e0e0f10e9acf148814a6e02fe42/tf_nightly_2.0_preview-2.0.0.dev20190829-cp36-cp36m-manylinux2010_x86_64.whl (89.1MB)\n",
            "\u001b[K     |████████████████████████████████| 89.1MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.33.4)\n",
            "Collecting opt-einsum>=2.3.2 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/1a/ab5683d8e450e380052d3a3e77bb2c9dffa878058f583587c3875041fb63/opt_einsum-3.0.1.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.8)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/96/497ea214af4bc285a95d749c8bfb6f246d79075cb585a21adcb3d18b991b/tensorflow_estimator_2.0_preview-1.14.0.dev2019082901-py2.py3-none-any.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 48.4MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.16.0a0,>=1.15.0a0 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/69/0216cd405af3161105e9a177e468296d2c444ddb347f597763d3f06f65b4/tb_nightly-1.15.0a20190828-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.16.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (41.2.0)\n",
            "Building wheels for collected packages: opt-einsum\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.0.1-cp36-none-any.whl size=58500 sha256=e4ee13b8057b9418f94c36842e8e549d048562c7f3f9dead819a0e66dfb31525\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/98/8d/10e3d4e04c959597a411b91acd3695e9e2d210e68ce3427aad\n",
            "Successfully built opt-einsum\n",
            "Installing collected packages: opt-einsum, tensorflow-estimator-2.0-preview, tb-nightly, tf-nightly-2.0-preview\n",
            "Successfully installed opt-einsum-3.0.1 tb-nightly-1.15.0a20190828 tensorflow-estimator-2.0-preview-1.14.0.dev2019082901 tf-nightly-2.0-preview-2.0.0.dev20190829\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KwgwYPiBzKR",
        "colab_type": "text"
      },
      "source": [
        "# Load and preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDK9dqrw7YNj",
        "colab_type": "text"
      },
      "source": [
        "## Use Pandas to create a dataframe\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) is a Python library with many helpful utilities for loading and working with structured data. We will use Pandas to download the dataset from mounted google drive, and load it into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7_n4-mbJG5I",
        "colab_type": "code",
        "outputId": "02d229ee-27c8-442d-84ad-97316e01337c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/collab data/titanic/train.csv')\n",
        "data.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJwsS34JXQC",
        "colab_type": "code",
        "outputId": "6703b82b-aa4a-45cb-8228-676a05952e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3FpQRY27qr2",
        "colab_type": "text"
      },
      "source": [
        "## Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdzyiTH17t9a",
        "colab_type": "text"
      },
      "source": [
        "### Check missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgIfUfC2Kbtf",
        "colab_type": "code",
        "outputId": "0a653869-a70b-4b98-c687-855b8a742efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtHcJuYE8iDx",
        "colab_type": "text"
      },
      "source": [
        "### Missing value handling\n",
        "\n",
        "As you can seee that there are some missing values in 'age' , 'embark' and 'cabin'. In 'cabin' number of missing values are large hence we delete this column from data, and in 'age' we will fill missing values with mean value and in 'embark' with most frequent value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IZp5IeSLhj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_value = round(data['Age'].mean())\n",
        "mode_value = data['Embarked'].mode()[0]\n",
        "\n",
        "value = {'Age': mean_value, 'Embarked': mode_value}\n",
        "data.fillna(value=value,inplace=True)\n",
        "\n",
        "data.dropna(axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDy7YX5iM0fG",
        "colab_type": "code",
        "outputId": "d16489ca-6a14-43b9-f877-13add2c0cd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYnPWav29fx9",
        "colab_type": "text"
      },
      "source": [
        "## Explore data with pandas_profiling library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRMZsdSJ27S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_profiling as pdpf\n",
        "pdpf.ProfileReport(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11KjNZGZKSSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdFkzjBBEhPc",
        "colab_type": "text"
      },
      "source": [
        "# Train, val, test Split\n",
        "\n",
        "We will divide data into train, validation, test data with 3:1:1 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cpfPx9kSI5K",
        "colab_type": "code",
        "outputId": "e0d48a63-11ec-4b56-cada-509812e6cb22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.25)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "534 train examples\n",
            "178 validation examples\n",
            "179 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VYULPCj90Ny",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAsyhqCV-G3a",
        "colab_type": "text"
      },
      "source": [
        "# Input pilpe line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqMcC0stErVu",
        "colab_type": "text"
      },
      "source": [
        "## Feature columns\n",
        "Know more about feature columns [here](https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJgTC8mJ-asb",
        "colab_type": "text"
      },
      "source": [
        "### Decide which types of features you have in data\n",
        "While data exploration you should note the types of features we have, for example, whether a feature is numerical or categorical, if it is numerical then can we categorize it into buckets or not, or if it is categorical then it should be checked how many categories are there, can we convert it into indicator columns or embedding column, are there any two feature, those can we combined to create new crossed feature. I will recommend you to read this very simplified [tutorial on feature columns](https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qBXyJIhKu2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_c = ['Age','Fare','Parch','SibSp']\n",
        "bucket_c  = ['Age']\n",
        "\n",
        "cat_i_c = ['Embarked', 'Pclass','Sex']\n",
        "cat_e_c = ['Ticket']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce2NhlYD-p9E",
        "colab_type": "text"
      },
      "source": [
        "### Scaler function\n",
        "It is very important for numerical variables to get scaled. here I have used min-max scaling. Here we are creating a function named 'get_scal' which takes list of numerical features and  returns 'minmax' function, which will be used in tf.feature_column.numeric_column() as normalizer_fn in parameters. 'minmax' function itself takes a 'numerical' number from a particular feature and return scaled value of that number. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEtgw9V9-x7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_scal(feature):\n",
        "  def minmax(x):\n",
        "    mini = train[feature].min()\n",
        "    maxi = train[feature].max()\n",
        "    return (x - mini)/(maxi-mini)\n",
        "  return(minmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr6lKWZT-95o",
        "colab_type": "text"
      },
      "source": [
        "### Creating feature columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoUEEJ7WSkS5",
        "colab_type": "code",
        "outputId": "516ea207-3e8d-46a5-d5f5-8c0c51d83354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Numerical columns\n",
        "feature_columns = []\n",
        "for header in num_c:\n",
        "  scal_input_fn = get_scal(header)\n",
        "  feature_columns.append(feature_column.numeric_column(header, normalizer_fn=scal_input_fn))\n",
        "\n",
        "# Bucketized columns\n",
        "Age = feature_column.numeric_column(\"Age\")\n",
        "age_buckets = feature_column.bucketized_column(Age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "feature_columns.append(age_buckets)\n",
        "\n",
        "# Categorical indicator columns\n",
        "for feature_name in cat_i_c:\n",
        "  vocabulary = data[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  one_hot = feature_column.indicator_column(cat_c)\n",
        "  feature_columns.append(one_hot)\n",
        "\n",
        "# Categorical embedding columns\n",
        "for feature_name in cat_e_c:\n",
        "  vocabulary = data[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  embeding = feature_column.embedding_column(cat_c, dimension=50)\n",
        "  feature_columns.append(embeding)\n",
        "\n",
        "# Crossed columns\n",
        "vocabulary = data['Sex'].unique()\n",
        "Sex = tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocabulary)\n",
        "\n",
        "crossed_feature = feature_column.crossed_column([age_buckets, Sex], hash_bucket_size=1000)\n",
        "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
        "feature_columns.append(crossed_feature)\n",
        "len(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuodVt5aFEsw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## Create an input data function using tf.data\n",
        "\n",
        "Next, we will wrap the dataframes with [tf.data](https://www.tensorflow.org/guide/datasets). This will enable us  to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model. If we were working with a very large CSV file (so large that it does not fit into memory), we would use tf.data to read it from disk directly. That is not covered in this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shDNA6m4Cjn7",
        "colab_type": "text"
      },
      "source": [
        "Here we will define a make_input_fn which will retrun input_function for data. The input_function specifies how data is converted to a tf.data.Dataset that feeds the input pipeline in a streaming fashion. tf.data.Dataset take take in multiple sources such as a dataframe, a csv-formatted file, and more. In tf.estimator we provide input function in model intead of data, but in dt.keras we can directly provide input data through input function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fquUsS2hUKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_input_fn(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('Survived')\n",
        "  def input_function():\n",
        "    \n",
        "    \n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds\n",
        "  return input_function\n",
        "\n",
        "\n",
        "train_input_fn = make_input_fn(train)\n",
        "eval_input_fn = make_input_fn(val,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_spfDUFYtQ",
        "colab_type": "text"
      },
      "source": [
        "# Train linear model\n",
        "After adding all the base features to the model, let's train the model. Training a model is just a single command using the tf.estimator API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAx6R6a8XJpc",
        "colab_type": "code",
        "outputId": "bbc9aa3b-e67f-4c03-d661-19ad77104bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "clear_output()\n",
        "print(result)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.8033708, 'accuracy_baseline': 0.6235955, 'auc': 0.87380666, 'auc_precision_recall': 0.8492318, 'average_loss': 0.47463596, 'label/mean': 0.3764045, 'loss': 0.47913766, 'precision': 0.92105263, 'prediction/mean': 0.34997383, 'recall': 0.52238804, 'global_step': 17}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSxEbsMgoPqx",
        "colab_type": "code",
        "outputId": "4e19e7e6-dc6d-41f6-f7e0-230f87369725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "print(pd.Series(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy                 0.803371\n",
            "accuracy_baseline        0.623595\n",
            "auc                      0.873807\n",
            "auc_precision_recall     0.849232\n",
            "average_loss             0.474636\n",
            "label/mean               0.376404\n",
            "loss                     0.479138\n",
            "precision                0.921053\n",
            "prediction/mean          0.349974\n",
            "recall                   0.522388\n",
            "global_step             17.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04fSJy06fcCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkTXp6ozFjfe",
        "colab_type": "text"
      },
      "source": [
        "# Train boosted Tree model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksGTObM2F3tN",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow boosted tree model does not support embeding column (aug 2019), hence creating feature columns without embedding column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlIQaaFjrVto",
        "colab_type": "code",
        "outputId": "5ba6c916-0366-490a-8a11-62e46dc95a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "feature_columns1 = list(set(feature_columns)-set([embeding]))\n",
        "feature_columns1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_scal.<locals>.minmax at 0x7f73e180bea0>),\n",
              " NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_scal.<locals>.minmax at 0x7f73e63b1e18>),\n",
              " IndicatorColumn(categorical_column=CrossedColumn(keys=(BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=1000, hash_key=None)),\n",
              " NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_scal.<locals>.minmax at 0x7f73e180bf28>),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Embarked', vocabulary_list=('S', 'C', 'Q'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Pclass', vocabulary_list=(3, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
              " NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_scal.<locals>.minmax at 0x7f73e63b1f28>),\n",
              " BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF3r3p5Qnv9H",
        "colab_type": "code",
        "outputId": "02c0ede2-3489-4197-d453-713600d0445b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "n_batches = 1\n",
        "est = tf.estimator.BoostedTreesClassifier(feature_columns1,\n",
        "                                          n_batches_per_layer=n_batches)\n",
        "\n",
        "# The model will stop training once the specified number of trees is built, not\n",
        "# based on the number of steps.\n",
        "est.train(train_input_fn)\n",
        "\n",
        "# Eval.\n",
        "result = est.evaluate(eval_input_fn)\n",
        "clear_output()\n",
        "print(pd.Series(result))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy                 0.797753\n",
            "accuracy_baseline        0.623595\n",
            "auc                      0.858747\n",
            "auc_precision_recall     0.809862\n",
            "average_loss             0.478607\n",
            "label/mean               0.376404\n",
            "loss                     0.484489\n",
            "precision                0.771930\n",
            "prediction/mean          0.395406\n",
            "recall                   0.656716\n",
            "global_step             16.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEAdwyWaFpSW",
        "colab_type": "text"
      },
      "source": [
        "# Problem test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYmYrqUJIuFd",
        "colab_type": "text"
      },
      "source": [
        "## Load and pre process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_K5RuiTt8D9",
        "colab_type": "code",
        "outputId": "a1b024ed-15f3-4872-9349-53ca5467b3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test_data = pd.read_csv('drive/My Drive/collab data/titanic/test.csv')\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJZChzrTuPV2",
        "colab_type": "code",
        "outputId": "913f8ffc-3268-43b8-fb9b-4ecae5034921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "test_data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age             86\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             1\n",
              "Cabin          327\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkjQfcXuR7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_value = round(data['Age'].mean())\n",
        "mean_value1 = data['Fare'].mean()\n",
        "\n",
        "value = {'Age': mean_value, 'Fare': mean_value1}\n",
        "test_data.fillna(value=value,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xxpisofv9CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data.dropna(axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Gf0xihvhwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MDnkI5I5Bf",
        "colab_type": "text"
      },
      "source": [
        "## Input function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og_XKAuZ6rQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_input_fn(features, batch_size=256):\n",
        "  def input_fn():\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "  return input_fn\n",
        "\n",
        "test_input = test_input_fn(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ahC9Hx7VRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7VKJ9jT6abE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk0ojmBJCuL",
        "colab_type": "text"
      },
      "source": [
        "## Prediction on linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0rCAx9GwK1f",
        "colab_type": "code",
        "outputId": "57e83d18-36a3-451e-d5eb-0a0fb2e272a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        }
      },
      "source": [
        "pred_dicts1 = list(linear_est.predict(test_input))\n",
        "probs1 = pd.Series([pred['probabilities'][1] for pred in pred_dicts1])\n",
        "\n",
        "predict_df_l = test_data[['PassengerId']]\n",
        "predict_df_l['Survived'] = (probs1>=.5).astype(int)\n",
        "predict_df_l.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0829 11:33:54.219903 140136900896640 base_layer.py:1820] Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>897</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>898</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>899</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>900</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>901</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         0\n",
              "5          897         0\n",
              "6          898         0\n",
              "7          899         0\n",
              "8          900         1\n",
              "9          901         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXqzfsd-JKPD",
        "colab_type": "text"
      },
      "source": [
        "## Prediction on boosted tree model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs2CY6FkwNKy",
        "colab_type": "code",
        "outputId": "04ad3cc4-c295-4313-9242-6239e5f7dca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "pred_dicts = list(est.predict(test_input))\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
        "predict_df_bt = test_data[['PassengerId']]\n",
        "predict_df_bt['Survived'] = (probs>=.5).astype(int)\n",
        "predict_df_bt.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>897</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>898</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>899</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>900</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>901</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         1\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         1\n",
              "5          897         0\n",
              "6          898         1\n",
              "7          899         0\n",
              "8          900         1\n",
              "9          901         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}